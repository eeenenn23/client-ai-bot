import os
import asyncio
import logging
import aiohttp

from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command

logging.basicConfig(level=logging.INFO)

BOT_TOKEN = os.getenv("BOT_TOKEN")
GROQ_TOKEN = os.getenv("GROQ_TOKEN")

bot = Bot(BOT_TOKEN)
dp = Dispatcher(bot=bot)

SYSTEM_PROMPT = """
–¢—ã –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤.
–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.
–ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å ‚Äî —É—Ç–æ—á–Ω–∏.
"""

@dp.message(Command("start"))
async def start(m: types.Message):
    await m.answer("üëã –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å.")

@dp.message()
async def chat(m: types.Message):
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {GROQ_TOKEN}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "llama-3.1-8b-instant",
                    "messages": [
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user", "content": m.text}
                    ],
                    "max_tokens": 150
                }
            ) as r:
                data = await r.json()

        await m.answer(data["choices"][0]["message"]["content"])

    except Exception as e:
        logging.error(e)
        await m.answer("‚ö†Ô∏è –í—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å.")

async def main():
    await dp.start_polling()

if __name__ == "__main__":
    asyncio.run(main())
